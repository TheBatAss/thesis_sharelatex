\chapter{Analysis}\label{anal_ch}
The previous Chapter described the most relevant work related to this thesis. This Chapter will analyze and describe the key concepts that will be used in this thesis.


\section{Self Tracking}
Experience Sampling Method (ESM) and Ecological Momentary Assessment (EMA) are the research methodologies that refer to the usage of self tracking\cite{esm}. What defines these methods are the use of collecting real world data in the moment, whether that be psychological (thoughts, feelings, mood, pain etc) or physical (food/drinks consumed, sneezing, cramps etc). Traditionally this had been achieved with diaries, which could have the same set of questions printed on each page designed to collect the desired data. In modern times digital diaries have been created, for example as apps on smartphones and smartwatches. The benefit of these methods is that the prevent recall bias, since the data is collected in the moment (or shortly after) compared to daily diaries where a user by the end of the day has to think back and recall the data. The more time passed between the event and the time the data is collected, the larger the risk of recall bias will be, and the data can even be forgotten.

When collecting data that requires active self tracking, there will always be a burden involved. The simpler the data is to collect, the smaller the burden can be. For example tracking each time a person sneezes only requires a time stamp which can be collected by wearing a smartbutton like the one made by Larsen et al.\cite{eg}. On the other hand, if tracking the pain levels of a patient, the patient needs a way to input that on scale preferably a VAS. One solution has been to create a digital VAS on a smartphone or smartwatch, similar to the work of Kami\'nski\cite{tomas}. Compared to the smartbutton, this solution has a much higher burden, the user must turn the display on, navigate the software to input the value and it requires a user's full attention to execute. With the improvements Dam-Jensen\cite{dam} introduced, the burden was lowered to only have the user press, hold and release a button while doing an arm gesture.

As a evolution to the design of Dam-Jensen\cite{dam}, this thesis will introduce a self tracking method where the user will follow the same gestures (described later in this Chapter) and press a button only once (not press, hold and release). This new method will reduce the burden even further compared to the other mentioned methods.


\section{Usage of VAS}
In Figure \ref{real_vas} we see one of the VAS rulers that is sold to and used by hospitals to measure the perceived pain level of patients, while they come in different designs their principals are the same. On one side of the ruler we see 5-6 faces with expression going from happy to discomfort to sad and crying, these expression are meant to illustrate the amount of pain and are often displayed together with a text description explaining the feeling of pain as seen in Figure \ref{vas_faces}. On the other side of the VAS ruler there is regular ruler of 10cm (sometimes shown as 100mm instead). On the ruler there is a slider, the patient will be shown the side of the ruler with the faces, and asked to adjust the slider to fit the level of pain they experience, on the backside the slider will indicate a position on the ruler from 0 (no pain) to 10 (most pain), this position is then registered by a doctor or nurse as the pain level. The VAS is not limited to measuring pain, it can be used for any subjective characteristics or attitudes that cannot be directly measured, for example mood, annoyance, anxiety, but the measuring of pain is the most common use of VAS.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figures/vas_faces.png}
    \caption{Example of faces and descriptions on VAS for measuring pain\cite{vas_faces}}
    \label{vas_faces}
\end{figure}

The VAS can be compared to the Likert scale and Borg scale\cite{borg_scale}, but what makes the VAS different is that it is continuous where the others are discrete. Evidence show that VAS have better metrical characteristics compared to discrete scales and therefore a wider range of statistical methods can be applied to the measurements\cite{best_scale}.

Despite its benefits VAS are a burden to use, even digital version since the require a screen and attention. It is therefore interesting to investigate if other solutions with less burden can perform equally or better than the VAS.



\section{Orientation in 3D Space}
Before creating a device that translates the orientation of the hand to a scale, one must first understand orientation in 3D space. We can rotate an object around each of its 3 axis, these actions are refereed to as pitch, roll and yaw. In Figure \ref{plane} we see an illustrations of these rotations performed on a airplane.

Pitch is rotation around the axis across the airplane, this rotation can be felt during takeoff and climbing (shortly after the wheels lift of the ground) of a airplane, where the pitch is dramatically changed from 0º (parallel to the ground) to $\thicksim$15-20º\cite{takeoff}.

Roll is rotation around the axis along the airplane, this rotation can sometimes be felt when an airplane has to perform a sharp turn and then rolls a little to one side so one wing tip is higher in the air than the other (when airplanes turn the yaw will also change), this rotational movement where the airplane rolls over is the roll axis.

Yaw is the rotation around the last axis, the same axis you would measure the height of airplane on. This rotation is barely felt in a airplane, but it is this orientation that will change the direction of the airplane, from lets say facing north to facing west by rotating 90º to the left (from the pilots perspective).

Getting the orientation of an object is then a matter of measuring the pitch, roll and yaw, there a different ways to do this and they will be discusses a little later, for now we will measure each rotation in degrees and define the orientation of 0º pitch, 0º roll and 0º yaw to be an object that is level in both directions and facing north. A full rotation in one axis is 360º and would leave the object in the same position as it started out. This definition is very similar to Euler angles witch will be discussed further.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figures/pitch_rool_yaw_v2.png}
    \caption{Pitch, roll and yaw of an airplane (edited version of figure found online\cite{plane})}
    \label{plane}
\end{figure}


\section{Inertial Measurement Unit}
In order to measure the orientation we will mount a device on the wrist which contains an Inertial Measurement Unit (IMU) from which the orientation can be read. Most IMUs are equipped with accelerometers, gyroscopes and magnetometers and offers either raw sensor values or the calculated Euler angles and quaternions for absolute orientation. In it self the raw sensor values can't provide the orientation, since it measures change for example the gyroscope alone will measure the rate of rotation, which in it self can't lead to an absolute orientation. But together the sensors provide enough data that this can be calculated, such an algorithm is called Sensor Fusion and is illustrated in Figure \ref{sensor_fusion}. Each IMU will have a different Sensor Fusion algorithm, and exactly was goes on is often a trade secret, but the pricnipal is as follows. The IMU will use its magnetometer to find north and use this to calibrate yaw, using its accelerometers the IMU can measure gravity and calibrate both pitch and roll. As a result of this yaw is measured from 0º to 360º independently (like a compass), pitch is measured from -180º to 180º degrees (0º to 180º is pointed towards the ground and -180º to 0º is pointed towards the sky) and roll is measured from -90º to 90º. Roll is dependent on pitch, which is why it only has a span of 180º instead of the full 360º. All together this lets the IMU calculate the absolute orientation. These calculations also requires the IMU to be calibrated and if not done correctly this can lead to issues, such as drift, where the orientation values will change even though the IMU sits completely still, this will be further investigated in Chapter \ref{implem_ch}. 


\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figures/SensorFusion.png}
    \caption{Model of Sensor Fusion algorithm (icons taken from Bosch\cite{bosch})}
    \label{sensor_fusion}
\end{figure}


The most common ways to represent absolute orientation is using either Euler angles\cite{euler} or quaternions\cite{quat}. Euler angles describes the orientation by angles of the 3 axis, this is the most intuitive approach but it has it downfall. When two of the gimbals in a gyroscope align into a parallel configuration, then one of the three degrees of freedom is lost, this is called Gimbal lock\cite{gimbal}. When Gimbal lock occurs changes in the locked axis cannot be measured, in order to fix it the axis which aligned itself with the other must be changed to get out of alignment and thus getting back the lost degree of freedom. This problem is often experienced in animation, where by defining movement only by total change in the three axis can cause strange and unintended results. The solution is to use quaternions, which is a mathematical number system which can represent the orientation of an object. Not getting into the math behind quaternions, but they solve the gimbal problem and quaternions can be transformed into Euler angles. Luckily when measuring the angles for the arm movements described gimbal lock does not occur, since the different axis does not come close to alignment in any position within the described movement. 